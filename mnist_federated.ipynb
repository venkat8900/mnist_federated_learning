{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_federated.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG55PPrMiLMe",
        "outputId": "5e4547e8-1c08-42b8-a228-935e8f8b5cd3"
      },
      "source": [
        "cd \"/content/drive/MyDrive/Colab Notebooks/Federated_mnist\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Federated_mnist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jywrEM0thq_e",
        "outputId": "17664211-561b-4b87-8c9b-f652868a6906"
      },
      "source": [
        "# install syft\r\n",
        "\r\n",
        "!pip install syft==0.1.29a1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft==0.1.29a1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/c7/2d5c1c04f025041764e875885f916f499cd26751ba888b64dddb4a651ba9/syft-0.1.29a1-py3-none-any.whl (322kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 13.9MB/s \n",
            "\u001b[?25hCollecting torchvision==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 27.8MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 60.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.1 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (1.19.5)\n",
            "Collecting tf-encrypted!=0.5.7,>=0.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/be/a4c0af9fdc5e5cee28495460538acf2766382bd572e01d4847abc7608dba/tf_encrypted-0.5.9-py3-none-manylinux1_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 48.3MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/06/f6501306032cd4015e220493514907864043376a02e83acc0be6bb1b98cf/lz4-3.1.1-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (1.0.2)\n",
            "Collecting flask-socketio>=3.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/05/ff/4de07d38fd2a4fb6326d96a2ecf9fb48026c3f064bc600f33fde0dc1c891/Flask_SocketIO-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (8.1)\n",
            "Collecting zstd>=1.4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/bc/6bc155c61db55d5b3111a8afc76aaec084372bde89a82ecd4f5fd96c639a/zstd-1.4.8.1.tar.gz (506kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (1.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.1.29a1) (0.22.2.post1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0->syft==0.1.29a1) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0->syft==0.1.29a1) (1.15.0)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 54.6MB/s \n",
            "\u001b[?25hCollecting tensorflow<2,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/6c/23c292d24b7861af55649f72f05faf0c379b75f75e89580d8a64657f77ad/tensorflow-1.15.5-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 31kB/s \n",
            "\u001b[?25hCollecting python-socketio>=5.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/76/071fed5787169c45f72e07b64d71c77761326d6b76471d9773fbff634ce7/python_socketio-5.0.4-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.1.29a1) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.1.29a1) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.1.29a1) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.1.29a1) (2.11.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft==0.1.29a1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft==0.1.29a1) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (0.10.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25hCollecting python-engineio>=4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/29/efdb97d117b0f6538b046b576e33c1cbd59b4d1c2959cf8d0f8089a8f1b4/python_engineio-4.0.0-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hCollecting bidict>=0.21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/d4/eaf9242722bf991e0955380dd6168020cb15a71cc0d3cc2373f4911b1f1d/bidict-0.21.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft==0.1.29a1) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (51.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft==0.1.29a1) (3.7.4.3)\n",
            "Building wheels for collected packages: zstd, pyyaml, gast\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zstd: filename=zstd-1.4.8.1-cp36-cp36m-linux_x86_64.whl size=1206050 sha256=740e094a62a77fb6da92cce06ec221686aa96611d3ff21dc3191acbc5abf5552\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/c3/7b/401864dafa21db92ecb4b1b73b0f6f66d0d9f0a7a1dce5e3a7\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=389aca4ecc1a97e5bbb619151ab8bda87d95d979a4eef251d8e40fa9f85e170d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=0ed1cffc57ab011a3760755b72df136b3af5fe77013cf00d9506a5d42e9341e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built zstd pyyaml gast\n",
            "\u001b[31mERROR: tensorflow 1.15.5 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torchvision, websocket-client, pyyaml, gast, tensorflow-estimator, tensorboard, keras-applications, tensorflow, tf-encrypted, lz4, python-engineio, bidict, python-socketio, flask-socketio, zstd, syft\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "  Found existing installation: syft 0.3.0\n",
            "    Uninstalling syft-0.3.0:\n",
            "      Successfully uninstalled syft-0.3.0\n",
            "Successfully installed bidict-0.21.2 flask-socketio-5.0.1 gast-0.2.2 keras-applications-1.0.8 lz4-3.1.1 python-engineio-4.0.0 python-socketio-5.0.4 pyyaml-5.3.1 syft-0.1.29a1 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1 tf-encrypted-0.5.9 torchvision-0.3.0 websocket-client-0.57.0 zstd-1.4.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTporqG1iWMm"
      },
      "source": [
        "Requirements: \r\n",
        "\r\n",
        "torch==1.1.0\r\n",
        "\r\n",
        "torchsummary==1.5.1\r\n",
        "\r\n",
        "torchtext==0.3.1\r\n",
        "\r\n",
        "torchvision==0.3.0\r\n",
        "\r\n",
        "syft==0.1.29a1\r\n",
        "\r\n",
        "numpy==1.16.4\r\n",
        "\r\n",
        "matplotlib==3.0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "G-uOf0sRidWY",
        "outputId": "8c98c801-bed4-4fd6-ef7f-f161c7de0462"
      },
      "source": [
        "!pip install torch==1.1.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.3.0 has requirement torch>=1.5, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed torch-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm-s4QIeijwA",
        "outputId": "fec03554-8105-4fcb-8969-80d0abcba8e5"
      },
      "source": [
        "!pip install torchsummary==1.5.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary==1.5.1 in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnU_w2NPil8K",
        "outputId": "1f076260-a389-441e-aba2-61bf05fc0b2c"
      },
      "source": [
        "!pip install torchtext==0.3.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.3.1 in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP3BVkoUipcW",
        "outputId": "d0b65152-6cc6-44ee-a8c9-7f1268dfd356"
      },
      "source": [
        "!pip install torchvision==0.3.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision==0.3.0 in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "vGE2nokBjqKA",
        "outputId": "5c369525-c654-418e-c3d5-6e55ab075dab"
      },
      "source": [
        "!pip install pillow==6.1 \r\n",
        "# Pillow 7.0.0 removed PILLOW_VERSION, you should use __version__ in your own code instead\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow==6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 12.6MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed pillow-6.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcR8H6vgh7VZ",
        "outputId": "62532c63-0d78-437c-fc81-cb7ef43917e4"
      },
      "source": [
        "import torch as th\r\n",
        "import numpy as np\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "from torch.utils.data import Subset\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import optim\r\n",
        "import syft as sy\r\n",
        "import helper\r\n",
        "\r\n",
        "#Hooking syft to torch\r\n",
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.5.so'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1mw755GiPo9"
      },
      "source": [
        "\r\n",
        "#Method to create 10 virtual workers and move to a list of workers\r\n",
        "# add more workers based on the workers(number of workers which trains the model with private data) you require. \r\n",
        "def create_workers():\r\n",
        "  workers = []\r\n",
        "  cartman = sy.VirtualWorker(hook, id = \"cartman\")\r\n",
        "  workers.append(cartman)\r\n",
        "  kyle = sy.VirtualWorker(hook, id = \"kyle\")\r\n",
        "  workers.append(kyle)\r\n",
        "  kenny = sy.VirtualWorker(hook, id = \"kenny\")\r\n",
        "  workers.append(kenny)\r\n",
        "  stan = sy.VirtualWorker(hook, id = \"stan\")\r\n",
        "  workers.append(stan)\r\n",
        "  butters = sy.VirtualWorker(hook, id = \"butters\")\r\n",
        "  workers.append(butters)\r\n",
        "  wendy = sy.VirtualWorker(hook, id = \"wendy\")\r\n",
        "  workers.append(wendy)\r\n",
        "  heidi = sy.VirtualWorker(hook, id = \"heidi\")\r\n",
        "  workers.append(heidi)\r\n",
        "  bebe = sy.VirtualWorker(hook, id = \"bebe\")\r\n",
        "  workers.append(bebe)\r\n",
        "  nichole = sy.VirtualWorker(hook, id = \"nichole\")\r\n",
        "  workers.append(nichole)\r\n",
        "  patty = sy.VirtualWorker(hook, id = \"patty\")\r\n",
        "  workers.append(patty)\r\n",
        "  return workers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHL9dK3zj-7W"
      },
      "source": [
        "#Method to clear out every tensor stored in the list of virtual workers\r\n",
        "def clear_workers(workers):\r\n",
        "  for worker in workers:\r\n",
        "    worker.clear_objects()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr_gzOp2kBJQ"
      },
      "source": [
        "# train loader and test loader for data splitting\r\n",
        "#Method to split the mnist test dataset into the various workers and also to load the mnist test dataset into a test loader\r\n",
        "def create_federated_and_test_loaders(workers, trainset, testset):\r\n",
        "  federated_train_loader = sy.FederatedDataLoader(\r\n",
        "      trainset.federate(workers), \r\n",
        "      batch_size=32, shuffle=True)\r\n",
        "\r\n",
        "  test_loader = th.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\r\n",
        "  return federated_train_loader, test_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyFrLSxukC9i"
      },
      "source": [
        "def create_train_federated_models(workers, loader, lr = 0.12, epoch = 5):\r\n",
        "  #sends model to first virtual worker\r\n",
        "  virtual_model = classifier().send(workers[0])\r\n",
        "  optimizer = optim.SGD(virtual_model.parameters(), lr)\r\n",
        "  criterion = nn.NLLLoss()\r\n",
        "  for n in range(epoch):\r\n",
        "    \r\n",
        "    #Integer to keep up with first index.\r\n",
        "    i = 0\r\n",
        "    \r\n",
        "    #Integer to keep up with current worker while training\r\n",
        "    j = 0\r\n",
        "    \r\n",
        "    #Integer to count number of mini-batches per worker\r\n",
        "    n_mbatch = 0\r\n",
        "    \r\n",
        "    #Variable to keep up with current worker while looping\r\n",
        "    dbLoc = None\r\n",
        "    \r\n",
        "    #Variable to store cummulative loss.\r\n",
        "    cum_loss = 0\r\n",
        "    \r\n",
        "    \r\n",
        "    for batch_idx, (imgs, labels) in enumerate(loader):\r\n",
        "      \r\n",
        "      #condition to set dbLoc to the first worker\r\n",
        "      if i == 0:\r\n",
        "        i = 2\r\n",
        "        dbLoc = imgs.location\r\n",
        "        \r\n",
        "      #condition to change dbLoc if img is stored on a different worker and also calculate loss\r\n",
        "      if dbLoc is not imgs.location:\r\n",
        "        print(\"The total loss for {0} for epoch {2} is {1}\".format(workers[j].id, cum_loss / n_mbatch, n+1))\r\n",
        "        dbLoc = imgs.location\r\n",
        "        j += 1\r\n",
        "        \r\n",
        "        #Moving the model to a new worker\r\n",
        "        virtual_model.move(dbLoc)\r\n",
        "        \r\n",
        "        #Resetting the cummulative loss and batch count to zero for new worker\r\n",
        "        cum_loss = 0\r\n",
        "        n_mbatch = 0\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      output = virtual_model.forward(imgs)\r\n",
        "      loss = criterion(output, labels)\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      cum_loss +=  loss.get().item()\r\n",
        "      n_mbatch += 1\r\n",
        "    print(\"The total loss for {0} is {1}\".format(workers[j].id, cum_loss / n_mbatch))\r\n",
        "    \r\n",
        "    #Moving the model to the first worker if training would occur again\r\n",
        "    if (n < (epoch - 1)):\r\n",
        "      virtual_model.move(workers[0])\r\n",
        "  return virtual_model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4TTVJ5SkIKu"
      },
      "source": [
        "#Method to return the model to the central machine\r\n",
        "def create_central_model(model):\r\n",
        "  return model.get()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0oyV7FGkKfC"
      },
      "source": [
        "#Method to analyze the private database with the trained model\r\n",
        "def analyze_model(model, loader):\r\n",
        "  print(\"Running on \", \"cpu\")\r\n",
        "  cum_perc = 0\r\n",
        "  for imgs, labels in loader:\r\n",
        "    with th.no_grad():\r\n",
        "      ps =  th.exp(model.forward(imgs))\r\n",
        "    top_p, top_class = ps.topk(1, dim = 1)\r\n",
        "    prob = top_class == labels.view(*top_class.shape)\r\n",
        "    prob = prob.float()\r\n",
        "    cum_perc += prob.mean().float()\r\n",
        "  print(\"The accuracy of the model is {0}%\".format((cum_perc / len(loader)) * 100))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FFhm6hlkN8p"
      },
      "source": [
        "#Classifier for creating the models\r\n",
        "class classifier(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__() \r\n",
        "    self.fc1 = nn.Linear(784, 256)\r\n",
        "    self.fc2 = nn.Linear(256, 128)\r\n",
        "    self.fc3 = nn.Linear(128, 64)\r\n",
        "    self.fc4 = nn.Linear(64, 32)\r\n",
        "    self.fc5 = nn.Linear(32, 10)\r\n",
        "    \r\n",
        "  def forward(self, x):\r\n",
        "    x = x.view(x.shape[0], -1)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = F.relu(self.fc3(x))\r\n",
        "    x = F.relu(self.fc4(x))\r\n",
        "    x = F.log_softmax(self.fc5(x), dim = 1)   \r\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY2Vf66wkQ2W",
        "outputId": "2c2b677d-2285-4718-ee00-2b570f138c53"
      },
      "source": [
        "# Application of transforms to normalize the mnist data\r\n",
        "transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\r\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\r\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 7656078.00it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 117617.27it/s]           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2423787.13it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 34064.70it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehXQTdzFkTdp"
      },
      "source": [
        "workers = create_workers()\r\n",
        "clear_workers(workers)\r\n",
        "federated_loader, test_loader = create_federated_and_test_loaders(workers, mnist_trainset, mnist_testset)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8OLFPk7kWBC",
        "outputId": "cf3b65cd-d096-4de3-a319-b1bbf0090b14"
      },
      "source": [
        "virtual_model = create_train_federated_models(workers, federated_loader, epoch = 2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total loss for cartman for epoch 1 is 2.307324820376457\n",
            "The total loss for kyle for epoch 1 is 2.3089127185496876\n",
            "The total loss for kenny for epoch 1 is 2.312258960084712\n",
            "The total loss for stan for epoch 1 is 2.3074064013805797\n",
            "The total loss for butters for epoch 1 is 2.3090646266937256\n",
            "The total loss for wendy for epoch 1 is 2.3092944457175886\n",
            "The total loss for heidi for epoch 1 is 2.307045430579084\n",
            "The total loss for bebe for epoch 1 is 2.310981546310668\n",
            "The total loss for nichole for epoch 1 is 2.310140146854076\n",
            "The total loss for patty is 2.3116971216303237\n",
            "The total loss for cartman for epoch 2 is 2.3074453726727913\n",
            "The total loss for kyle for epoch 2 is 2.3089565482545407\n",
            "The total loss for kenny for epoch 2 is 2.3121859393221267\n",
            "The total loss for stan for epoch 2 is 2.3074388225027858\n",
            "The total loss for butters for epoch 2 is 2.3092057007424374\n",
            "The total loss for wendy for epoch 2 is 2.3092764045329806\n",
            "The total loss for heidi for epoch 2 is 2.3072677077131067\n",
            "The total loss for bebe for epoch 2 is 2.311253214136083\n",
            "The total loss for nichole for epoch 2 is 2.3102816875944745\n",
            "The total loss for patty is 2.3115286827087402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyv54KEykYgs"
      },
      "source": [
        "central_model = create_central_model(virtual_model)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRTk6rUkav6",
        "outputId": "310619f5-681a-4fb2-f76b-98fe962d4c13"
      },
      "source": [
        "analyze_model(central_model, test_loader)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on  cpu\n",
            "The accuracy of the model is 9.802946090698242%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEdHs_lgkclW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}